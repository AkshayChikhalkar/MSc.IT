\section{Task Solution by State-of-the-Art Classification Methods}
	\subsection{What is ML?}
	Machine learning is a subfield of computer science that aims to allow computers to "learn" without being explicitly programmed \cite{C0}. It has its roots in the 1950s artificial intelligence movement and emphasises practical goals and applications, particularly prediction and optimization. In machine learning, computers "learn" by improving their performance at tasks through "experience" \cite{C01}.
	\subsection{Why ML?}
	A branch of computing algorithms called machine learning is constantly developing and aims to replicate human intelligence by learning from the environment. In the new era of 'big data,' they are regarded as the workhorse. Machine learning methods have been effectively used in a variety of industries, including banking, entertainment, biomedicine, pattern recognition, computer vision, spacecraft engineering and computational biology. In addition, it has readily available libraries to perform tasks like clustering, classification etc. Hence, ML is the perfect solution to classification.\\
	\subsection{Machine Learning Overview}
	Here is a brief overview of some of the most popular machine learning algorithms\cite{C2}.\\	
	\begin{figure}[H]
		\begin{tikzpicture}[
			level 1/.style={sibling distance=40mm},
			edge from parent/.style={->,draw},
			>=latex]
			
			% root of the the initial tree, level 1
			\node[root] {Machine Learning}
			% The first level, as children of the initial tree
			child {node[level 2] (c3) {Supervised Learning}
				child {node[level 3, anchor=west] (c4) {Regression}}
				child {node[level 3, anchor=west] (c5) {Classification}}}
			child {node[level 2] (c2) {Unsupervised Learning}};
			
			% The second level, relatively positioned nodes
			\begin{scope}[every node/.style={level 4},node distance=1.3cm, auto]
				
				\node [below of = c5, xshift=15pt] (c51) {Logistic Regression};
				\node [below of = c51] (c52) {Decision Tree};
				\node [below of = c52] (c53) {Random Forest};
				\node [below of = c53] (c54) {Support Vector Machine};
				\node [below of = c54] (c55) {Multi-layer Perceptron};
				
				\node [below of = c4, xshift=15pt] (c41) {Linear Regression};
				\node [below of = c41] (c42) {Neural Networks};
				\node [below of = c42] (c43) {Decision Tree};
				\node [below of = c43] (c44) {Ensemble Methods};
				\node [below of = c44] (c45) {Stochastic Gradient Descent};
			\end{scope}
			
			% lines from each level 1 node to every one of its "children"
			\foreach \value in {1,...,5}
			\draw[->] (c4.195) |- (c4\value.west);
			
			\foreach \value in {1,...,5}
			\draw[->] (c5.195) |- (c5\value.west);
		\end{tikzpicture}
	\caption[]{Machine learning classification tree diagram}
	\label{ML Tree Diagram}
	\end{figure}	
	Machine learning is classified into Supervised Learning and Unsupervised Learning along with others like Semi-Supervised Learning, Reinforcement Learning, Multi-task Learning, Ensemble Learning, Neural Networks and Instance-Based Learning \cite{C2}.\\ 
	Unsupervised learning is a form of machine learning technique that unearths obscure patterns or data clusters without the assistance of a human \cite{C4}.\\
	
	In this paper, supervised learning was studied. It is machine learning algorithm that can develop broad patterns and hypotheses by using examples from outside sources to predict the results of incoming examples. The goal of supervised machine learning classification algorithms is to classify data based on existing knowledge (Labelled data) \cite{C3}. Supervised Learning is further categorised into two parts i.e. Regression and Classification.\\
	Regression is frequently used for forecasting and prediction, two areas where machine learning and their application have a lot in common. \\
	
	Supervised classification is one of the functions that so-called intelligent systems carry out most frequently\cite{C7}. The goal of supervised learning is to create a precise model of the distribution of class labels in terms of predictor features. When the values of the predictor characteristics are known but the value of the class label is unknown, the resulting classifier is used to give class labels to the testing cases. In this paper, we focus on the classification of GPU based on memory type (Target variable).\\
	Classification is a data mining technique used to predict data instance group membership\cite{C9}\\
	\begin{figure}[H]
		\resizebox{9cm}{!}{
		\begin{tikzpicture}[
			level 1/.style={sibling distance=40mm},
			edge from parent/.style={->,draw},
			>=latex]
			
			% root of the the initial tree, level 1
			\node[root,font=\large, text width=4cm, minimum height=1cm] {Classification}
			% The first level, as children of the initial tree
			child {node[level 2, text width=3cm, font=\large,minimum height=0.8cm] (c3) {Single Label}
				child {node[level 3,font=\large,text width=2cm,minimum height=0.7cm] {Binary}}
				child {node[level 3,font=\large,text width=2cm,minimum height=0.7cm] {Multi-class}}}
			child {node[level 2, text width=3cm,font=\large, minimum height=0.8cm] (c2) {Multi Label}
				child {node[level 3, below=2cm,font=\large] {Problem Transformation Methods}}
				child {node[level 3, below=2cm,font=\large] {Algorithm Adaptation Methods}}};
		\end{tikzpicture}
		}
		\caption{Types of classification techniques}
		\label{Classification Tree Diagram}
	\end{figure}

	Most classification problems assign a single class to each example or instance\cite{b1}. However, there are many classification tasks in which each instance can be assigned to one or more classes. This set of problems falls under the category of multi-label classification\cite{C10}. Multi-label classification is further categorised into two types, Problem Transformation Methods and  Algorithm Adaptation Methods.\\ 
	
	Part of single label classification technique, binary classification is a supervised learning algorithm that categorizes new observations into one of two classes\cite{C13}. \\
	A multiclass classification task is a machine learning classification task with more than two classes or outputs\cite{C14}. It assumes that each sample has only one label and employs the Bayes theorem to predict the class of unknown datasets\cite{C14}.\\	
	
	A study presents a network kernel function called Multi-field packet classification, which classifies and routes packets on a GPU using a set of rules\cite{C15}. Another study utilizes a shapelet discovery algorithm for time series classification, which identifies useful subsequences from a set of time series\cite{C16}. The study notes that with recent advancements in high-performance computing techniques, such as GPU, large-scale deep learning models are now possible for machine learning applications\cite{C17}. However, there is a lack of research on CPU classification. To address this gap, the study conducts GPU classification using different types of graphics memory and evaluates and compares three classification algorithms (Random Forest, Support Vector Classification and Decision Tree classifier).
